# -*- coding: utf-8 -*-
"""Attrition.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/16SeN8Qf7LfgXC7qVICBfWLIeB2fj2Cuf
"""

from google.colab import drive
drive.mount('/content/drive')

#Importing the libraries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

#Reading the data
dataset=pd.read_excel('/content/drive/MyDrive/All_employees.xlsx')
dataset.head()

#Choosing our variables
X=dataset.iloc[:,2:7].values
print (X)
Y=dataset.iloc[:,0].values
print (Y)

#Examining the data
dataset.dtypes

#Dropping irrelevant columns
dataset.drop(['Emp_ID','Department'],axis=1,inplace=True)

#Checking if irrelevant columns have been dropped
dataset.head()

#Encoding columns to binary variables
from sklearn.preprocessing import LabelEncoder
le=LabelEncoder()
dataset.Employee_Status=le.fit_transform(dataset.Employee_Status)
dataset.Salary=le.fit_transform(dataset.Salary)

dataset.head()

#Grouping dataset by employee status
ex_employees=dataset.groupby('Employee_Status')
ex_employees.mean()

#Identifying correlation between variables
import seaborn as sns
corr=dataset.corr()
ax=sns.heatmap(corr,annot=True)

#Identifying number of clusters to group the data by Elbow Method
wcss=[]
from sklearn.cluster import KMeans
for i in range(1,9):
    kmeans = KMeans(n_clusters=i, init='k-means++', n_init=8, max_iter=300, random_state=0)
    kmeans.fit(X)
    wcss.append(kmeans.inertia_)

plt.plot(range(1,9), wcss)
plt.title('Elbow Method')
plt.xlabel('Number of Clusters')
plt.ylabel('wcss')
plt.show()

#Segmentation 1
from sklearn.cluster import KMeans
gone_emp =  dataset[['Last_Evaluation','Average_monthly_hours']][dataset.Employee_Status == 1]
# Create groups using K-means clustering.
kmeans = KMeans(n_clusters = 3, random_state = 0).fit(gone_emp)

gone_emp['label'] = kmeans.labels_
plt.scatter(gone_emp['Last_Evaluation'], gone_emp['Average_monthly_hours'], c=gone_emp['label'],cmap='Accent')
plt.xlabel('Last_Evaluation')
plt.ylabel('Average_monthly_hours')
plt.title('Cluster of employees who left')
plt.savefig('Segmentation 1')
plt.show()

#Segmentation 2
from sklearn.cluster import KMeans
gone_emp =  dataset[['Last_Evaluation','Number_of_projects']][dataset.Employee_Status == 1]
# Create groups using K-means clustering.
kmeans = KMeans(n_clusters = 3, random_state = 0).fit(gone_emp)

gone_emp['label'] = kmeans.labels_
plt.scatter(gone_emp['Last_Evaluation'], gone_emp['Number_of_projects'], c=gone_emp['label'],cmap='Accent')
plt.xlabel('Last_Evaluation')
plt.ylabel('Number_of_projects')
plt.title('Cluster of employees who left')
plt.savefig('Segmentation 2')
plt.show()

#Segmentation 3
from sklearn.cluster import KMeans
gone_emp =  dataset[['Average_monthly_hours','Number_of_projects']][dataset.Employee_Status == 1]
# Create groups using K-means clustering.
kmeans = KMeans(n_clusters = 3, random_state = 0).fit(gone_emp)

gone_emp['label'] = kmeans.labels_
plt.scatter(gone_emp['Average_monthly_hours'], gone_emp['Number_of_projects'], c=gone_emp['label'],cmap='Accent')
plt.xlabel('Average_monthly_hours')
plt.ylabel('Number_of_projects')
plt.title('Cluster of employees who left')
plt.savefig('Segmentation 3')
plt.show()

#Segmentation 4
from sklearn.cluster import KMeans
gone_emp =  dataset[['Salary','Average_monthly_hours']][dataset.Employee_Status == 1]
# Create groups using K-means clustering.
kmeans = KMeans(n_clusters = 3, random_state = 0).fit(gone_emp)

gone_emp['label'] = kmeans.labels_
plt.scatter(gone_emp['Salary'], gone_emp['Average_monthly_hours'], c=gone_emp['label'],cmap='Accent')
plt.xlabel('Salary')
plt.ylabel('Average_monthly_hours')
plt.title('Cluster of employees who left')
plt.savefig('Segmentation 4')
plt.show()

#RandomForestClassifier
from sklearn.ensemble import RandomForestClassifier   
from sklearn.model_selection import train_test_split
X_train,X_test,Y_train,Y_test=train_test_split(X,Y,test_size=0.2,random_state=0)
rf = RandomForestClassifier(n_estimators=7,criterion='entropy',random_state=0) 
rf.fit(X_train, Y_train)

#Predicting Y
Y_pred = rf.predict(X_test) 
Y_pred

#Building a confusion matrix
from sklearn.metrics import confusion_matrix
rf_confusion_matrix = confusion_matrix(Y_test,Y_pred)
sns.heatmap(rf_confusion_matrix, annot=True, fmt='.2f',xticklabels = ['Ex', 'Current'] , yticklabels = ['Ex', 'Current'] )
plt.ylabel('Actual class')
plt.xlabel('Predicted class')
plt.title('Random Forest Classifier')

#Testing for model accuracy
accuracy_score = rf.score(X_train,Y_train)
print(accuracy_score)